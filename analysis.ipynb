{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud\n",
    "from google.cloud import language_v1\n",
    "import io\n",
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"lustrous-center-305403-9cd548f48b67.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "data_test = pd.read_csv('religious_text_test.csv')\n",
    "data_train = pd.read_csv('religious_text_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values\n",
    "data_train[:] = data_train.fillna(0)\n",
    "data_test[:] = data_test.fillna(0)\n",
    "\n",
    "# rename the unnamed column to Chapters, '# foolishness' to just foolishness\n",
    "data_train.rename(columns = {'Unnamed: 0' : 'Chapters'}, inplace = True)\n",
    "data_test.rename(columns = {'# foolishness' : 'foolishness'}, inplace = True)\n",
    "\n",
    "# make sure everything is an integer\n",
    "data_test = data_test.applymap(int).astype(int)\n",
    "data_train.iloc[:, 1:] = data_train.iloc[:, 1:].applymap(int).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data validation stuff, more cleaning\n",
    "\n",
    "all(data_train.iloc[:,1:].dtypes == 'int64') # True (All entries are integers)\n",
    "all(data_test.dtypes == 'int64') # True (All entries are integers)\n",
    "\n",
    "all(list(map(lambda a: ' ' not in a, data_train.iloc[:,1:].columns))) # Each column is one word\n",
    "all(list(map(lambda a: ' ' not in a, data_test.columns))) # Each column is one word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data to work with \n",
    "\n",
    "\n",
    "# Extraaaaaa way of getting the books lmao, dont do this\n",
    "books = [i[0] for i in list(map(lambda a: a.split('_'), data_train['Chapters'].unique())) if i[1] == 'Ch1']\n",
    "\n",
    "# dataframes segregated by chapters\n",
    "book_list = [data_train[[j in i for i in data_train['Chapters']]] for j in books]\n",
    "\n",
    "# top 20 words for each book in a list containing 8 series\n",
    "top_20_books = [j.sort_values(ascending = False) for j in [i.iloc[:,1:].sum() for i in book_list]]\n",
    "\n",
    "# total words in each book\n",
    "total_words_book = dict(zip(books, [i.sum() for i in top_20_books]))\n",
    "\n",
    "# total words in each chapter of each book (dictionary)\n",
    "total_words_chapter = dict(zip(books,[pd.Series(data=i.iloc[:,1:].sum(axis=1).tolist(), index=i.iloc[:,0]) for i in book_list]))\n",
    "\n",
    "# Top 20 words for all books\n",
    "all_20 = data_train.iloc[:,1:].sum().sort_values(ascending = False)\n",
    "\n",
    "# total words in the dataframe \n",
    "total_words = all_20.sum()\n",
    "\n",
    "# proportion of words in the top 20 over total words in each book \n",
    "prop_20_book = dict(zip(books,[top_20_books[i][:20].sum() / [j.sum() for j in top_20_books][i] for i in range(8)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word cloud visualizations (ready for graphing)\n",
    "\n",
    "mask = np.array(Image.open(\"book.png\"))\n",
    "\n",
    "# for all books in total\n",
    "desc = all_20.index.tolist(); counts = all_20.tolist()\n",
    "wordcloud_20 = WordCloud(mask = mask, max_words = len(all_20)).generate_from_frequencies(dict(zip(desc,counts))) # stored here\n",
    "\n",
    "# for each book (in a list)\n",
    "word_cloud_each = [] # all in this list\n",
    "for i in top_20_books:\n",
    "    desc = i[:20].index.tolist(); counts = i[:20].tolist()\n",
    "    word_cloud_each.append(WordCloud(max_words = 20).generate_from_frequencies(dict(zip(desc,counts))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code basically takes all scores calculated from the sentiment analysis text file,\n",
    "# in order to help with sentiment score calculations \n",
    "\n",
    "sentiments = open('sentiment_analysis.txt', 'r')\n",
    "scores = [float(line.split(' ')[3].strip()) for line in sentiments.readlines() if 'score' in line and 'Document' in line][1:]\n",
    "sentiments.seek(0)\n",
    "magnitude = [float(line.split(' ')[3].strip()) for line in sentiments.readlines() if 'magnitude' in line and 'Document' in line][1:]\n",
    "sentiments.seek(0)\n",
    "keys = [line.strip() for line in sentiments.readlines() if ' ' not in line and line.rstrip()]\n",
    "scores_dict = dict(zip(keys,scores))\n",
    "magnitude_dict = dict(zip(keys,magnitude))\n",
    "\n",
    "# function to calculate sentiment scores\n",
    "book_scores = list(map((lambda j: sum([scores_dict[k] * j[i] for i,k in enumerate(j.index.tolist())]) / sum(j.tolist())), top_20_books))\n",
    "magnitude_scores = list(map((lambda j: sum([magnitude_dict[k] * j[i] for i,k in enumerate(j.index.tolist())]) / sum(j.tolist())), top_20_books))\n",
    "top_20_scores = list(map((lambda j: sum([scores_dict[k] * j[:20][i] for i,k in enumerate(j[:20].index.tolist())]) / sum(j[:20].tolist())), top_20_books))\n",
    "top_20_magnitude = list(map((lambda j: sum([magnitude_dict[k] * j[:20][i] for i,k in enumerate(j[:20].index.tolist())]) / sum(j[:20].tolist())), top_20_books))\n",
    "\n",
    "scores_20 = dict(zip(books,list(top_20_scores)))\n",
    "magnitude_20 = dict(zip(books,list(top_20_magnitude)))\n",
    "book_scores_dict = dict(zip(books,list(book_scores)))\n",
    "book_magnitude_dict = dict(zip(books,list(magnitude_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Buddhism': 0.24219505243556763,\n",
       " 'TaoTeChing': 0.2704861143008909,\n",
       " 'Upanishad': 0.25052439940317295,\n",
       " 'YogaSutra': 0.25580648164577946,\n",
       " 'BookOfProverb': 0.2854328706238695,\n",
       " 'BookOfEcclesiastes': 0.26505589974171584,\n",
       " 'BookOfEccleasiasticus': 0.2743513750982972,\n",
       " 'BookOfWisdom': 0.27575094851301896}"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_magnitude_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Buddhism': 0.09615036416551377,\n",
       " 'TaoTeChing': 0.10507812653344849,\n",
       " 'Upanishad': 0.14579723597927322,\n",
       " 'YogaSutra': 0.1536446225476219,\n",
       " 'BookOfProverb': 0.11912908512633535,\n",
       " 'BookOfEcclesiastes': 0.10775333822977229,\n",
       " 'BookOfEccleasiasticus': 0.1323606737575101,\n",
       " 'BookOfWisdom': 0.11163716152331121}"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Buddhism': 0.12714171554562184,\n",
       " 'TaoTeChing': 0.12188365487923583,\n",
       " 'Upanishad': 0.185788385794185,\n",
       " 'YogaSutra': 0.29939333488458447,\n",
       " 'BookOfProverb': 0.2113649379536467,\n",
       " 'BookOfEcclesiastes': 0.1680791009280641,\n",
       " 'BookOfEccleasiasticus': 0.21494290865896964,\n",
       " 'BookOfWisdom': 0.20057537840514245}"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Buddhism': 0.2459567718154149,\n",
       " 'TaoTeChing': 0.24016620511823744,\n",
       " 'Upanishad': 0.2505186763495454,\n",
       " 'YogaSutra': 0.3062689669385055,\n",
       " 'BookOfProverb': 0.291319248413849,\n",
       " 'BookOfEcclesiastes': 0.25000000458821064,\n",
       " 'BookOfEccleasiasticus': 0.24665579735795204,\n",
       " 'BookOfWisdom': 0.20655926802250266}"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "magnitude_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
