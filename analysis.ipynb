{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from google.cloud import language_v1\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "data_test = pd.read_csv('religious_text_test.csv')\n",
    "data_train = pd.read_csv('religious_text_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values\n",
    "data_train[:] = data_train.fillna(0)\n",
    "data_test[:] = data_test.fillna(0)\n",
    "\n",
    "# rename the unnamed column to Chapters, '# foolishness' to just foolishness\n",
    "data_train.rename(columns = {'Unnamed: 0' : 'Chapters'}, inplace = True)\n",
    "data_test.rename(columns = {'# foolishness' : 'foolishness'}, inplace = True)\n",
    "\n",
    "# make sure everything is an integer\n",
    "data_test = data_test.applymap(int).astype(int)\n",
    "data_train.iloc[:, 1:] = data_train.iloc[:, 1:].applymap(int).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data validation stuff, more cleaning\n",
    "\n",
    "all(data_train.iloc[:,1:].dtypes == 'int64') # True (All entries are integers)\n",
    "all(data_test.dtypes == 'int64') # True (All entries are integers)\n",
    "\n",
    "all(list(map(lambda a: ' ' not in a, data_train.iloc[:,1:].columns))) # Each column is one word\n",
    "all(list(map(lambda a: ' ' not in a, data_test.columns))) # Each column is one word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extraaaaaa way of getting the books lmao, dont do this\n",
    "books = [i[0] for i in list(map(lambda a: a.split('_'), data_train['Chapters'].unique())) if i[1] == 'Ch1']\n",
    "\n",
    "# dataframes segregated by chapters\n",
    "book_list = [data_train[[j in i for i in data_train['Chapters']]] for j in books]\n",
    "\n",
    "# top 20 words for each book in a list containing 8 series\n",
    "top_20_books = [j.sort_values(ascending = False) for j in [i.iloc[:,1:].sum() for i in book_list]]\n",
    "\n",
    "# total words in each book\n",
    "total_words_book = dict(zip(books, [i.sum() for i in top_20_books]))\n",
    "\n",
    "# total words in each chapter of each book (dictionary)\n",
    "total_words_chapter = dict(zip(books,[pd.Series(data=i.iloc[:,1:].sum(axis=1).tolist(), index=i.iloc[:,0]) for i in book_list]))\n",
    "\n",
    "# Series for each book (Top 20 Words)\n",
    "buddhism_20 = top_20_books[0]; tao_20 = top_20_books[1]\n",
    "upanishad_20 = top_20_books[2]; yoga_20 = top_20_books[3]\n",
    "proverb_20 = top_20_books[4]; ecclesiastes_20 = top_20_books[5]\n",
    "eccleasiasticus_20 = top_20_books[6]; wisdom_20 = top_20_books[7]\n",
    "\n",
    "# Top 20 words for all books\n",
    "all_20 = data_train.iloc[:,1:].sum().sort_values(ascending = False)\n",
    "# total words in the dataframe \n",
    "tototal_words = all_20.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word cloud visualizations (ready for graphing)\n",
    "\n",
    "mask = np.array(Image.open(\"book.png\"))\n",
    "\n",
    "# for all books in total\n",
    "desc = all_20.index.tolist(); counts = all_20.tolist()\n",
    "wordcloud_20 = WordCloud(mask = mask, max_words = len(all_20)).generate_from_frequencies(dict(zip(desc,counts))) # stored here\n",
    "\n",
    "# for each book (in a list)\n",
    "word_cloud_each = [] # all in this list\n",
    "for i in top_20_books:\n",
    "    desc = i[:20].index.tolist(); counts = i[:20].tolist()\n",
    "    word_cloud_each.append(WordCloud(max_words = 20).generate_from_frequencies(dict(zip(desc,counts))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8999999761581421"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"lustrous-center-305403-9cd548f48b67.json\"\n",
    "\n",
    "def analyze_sentiment(text_content):\n",
    "    client = language_v1.LanguageServiceClient()\n",
    "\n",
    "    # Available types: PLAIN_TEXT, HTML\n",
    "    type_ = language_v1.Document.Type.PLAIN_TEXT\n",
    "\n",
    "    # Optional. If not specified, the language is automatically detected.\n",
    "    # For list of supported languages:\n",
    "    # https://cloud.google.com/natural-language/docs/languages\n",
    "    language = \"en\"\n",
    "    document = {\"content\": text_content, \"type_\": type_, \"language\": language}\n",
    "\n",
    "    # Available values: NONE, UTF8, UTF16, UTF32\n",
    "    encoding_type = language_v1.EncodingType.UTF8\n",
    "\n",
    "    response = client.analyze_sentiment(request = {'document': document, 'encoding_type': encoding_type})\n",
    "    # Get overall sentiment of the input document\n",
    "    \n",
    "    #print(u\"Document sentiment score: {}\".format(response.document_sentiment.score))\n",
    "    return response.document_sentiment.score\n",
    "        \n",
    "\n",
    "\n",
    "    # Get the language of the text, which will be the same as\n",
    "    # the language specified in the request or, if not specified,\n",
    "    # the automatically-detected language.\n",
    "    #print(u\"Language of the text: {}\".format(response.language))\n",
    "    #print(text_content)\n",
    "    \n",
    "\n",
    "analyze_sentiment(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document sentiment score: 0.30000001192092896\n",
      "Document sentiment magnitude: 0.30000001192092896\n",
      "Document sentiment score: 0.30000001192092896\n",
      "Document sentiment magnitude: 0.30000001192092896\n",
      "Document sentiment score: 0.10000000149011612\n",
      "Document sentiment magnitude: 0.10000000149011612\n",
      "Document sentiment score: -0.6000000238418579\n",
      "Document sentiment magnitude: 0.6000000238418579\n",
      "Document sentiment score: 0.10000000149011612\n",
      "Document sentiment magnitude: 0.10000000149011612\n",
      "Document sentiment score: 0.0\n",
      "Document sentiment magnitude: 0.0\n",
      "Document sentiment score: 0.10000000149011612\n",
      "Document sentiment magnitude: 0.10000000149011612\n",
      "Document sentiment score: 0.0\n",
      "Document sentiment magnitude: 0.0\n",
      "Document sentiment score: -0.20000000298023224\n",
      "Document sentiment magnitude: 0.20000000298023224\n",
      "Document sentiment score: 0.0\n",
      "Document sentiment magnitude: 0.0\n",
      "Document sentiment score: -0.30000001192092896\n",
      "Document sentiment magnitude: 0.30000001192092896\n",
      "Document sentiment score: 0.30000001192092896\n",
      "Document sentiment magnitude: 0.30000001192092896\n",
      "Document sentiment score: 0.5\n",
      "Document sentiment magnitude: 0.5\n",
      "Document sentiment score: 0.20000000298023224\n",
      "Document sentiment magnitude: 0.20000000298023224\n",
      "Document sentiment score: 0.4000000059604645\n",
      "Document sentiment magnitude: 0.4000000059604645\n",
      "Document sentiment score: 0.5\n",
      "Document sentiment magnitude: 0.5\n",
      "Document sentiment score: 0.0\n",
      "Document sentiment magnitude: 0.0\n",
      "Document sentiment score: 0.6000000238418579\n",
      "Document sentiment magnitude: 0.6000000238418579\n",
      "Document sentiment score: 0.4000000059604645\n",
      "Document sentiment magnitude: 0.4000000059604645\n",
      "Document sentiment score: 0.20000000298023224\n",
      "Document sentiment magnitude: 0.20000000298023224\n",
      "Document sentiment score: -0.4000000059604645\n",
      "Document sentiment magnitude: 0.4000000059604645\n",
      "Document sentiment score: 0.0\n",
      "Document sentiment magnitude: 0.0\n",
      "Document sentiment score: 0.10000000149011612\n",
      "Document sentiment magnitude: 0.10000000149011612\n",
      "Document sentiment score: 0.30000001192092896\n",
      "Document sentiment magnitude: 0.30000001192092896\n",
      "Document sentiment score: 0.8999999761581421\n",
      "Document sentiment magnitude: 0.8999999761581421\n",
      "Document sentiment score: -0.10000000149011612\n",
      "Document sentiment magnitude: 0.10000000149011612\n",
      "Document sentiment score: 0.8999999761581421\n",
      "Document sentiment magnitude: 0.8999999761581421\n",
      "Document sentiment score: 0.10000000149011612\n",
      "Document sentiment magnitude: 0.10000000149011612\n",
      "Document sentiment score: 0.0\n",
      "Document sentiment magnitude: 0.0\n",
      "Document sentiment score: 0.0\n",
      "Document sentiment magnitude: 0.0\n",
      "Document sentiment score: 0.0\n",
      "Document sentiment magnitude: 0.0\n",
      "Document sentiment score: 0.0\n",
      "Document sentiment magnitude: 0.0\n",
      "Document sentiment score: 0.20000000298023224\n",
      "Document sentiment magnitude: 0.20000000298023224\n",
      "Document sentiment score: 0.0\n",
      "Document sentiment magnitude: 0.0\n",
      "Document sentiment score: -0.10000000149011612\n",
      "Document sentiment magnitude: 0.10000000149011612\n",
      "Document sentiment score: 0.20000000298023224\n",
      "Document sentiment magnitude: 0.20000000298023224\n",
      "Document sentiment score: 0.800000011920929\n",
      "Document sentiment magnitude: 0.800000011920929\n",
      "Document sentiment score: -0.10000000149011612\n",
      "Document sentiment magnitude: 0.10000000149011612\n",
      "Document sentiment score: 0.0\n",
      "Document sentiment magnitude: 0.0\n",
      "Document sentiment score: 0.30000001192092896\n",
      "Document sentiment magnitude: 0.30000001192092896\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tao' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-ef1db0d028ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbuddhist_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0manalyze_sentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuddhism_20\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbuddhism_20\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuddhism_20\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtao_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0manalyze_sentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtao_20\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtao_20\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtao\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tao' is not defined"
     ]
    }
   ],
   "source": [
    "buddhist_score = sum([analyze_sentiment(buddhism_20[:20].index.tolist()[i]) * buddhism_20[i] for i in range(20)]) / sum(buddhism_20[:20].tolist())\n",
    "tao_score = sum([analyze_sentiment(tao_20[:20].index.tolist()[i]) * tao_20[i] for i in range(20)]) / sum(tao[:20].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "total_words_book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
